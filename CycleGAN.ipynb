{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cycle-GAN implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Dataset Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a GAN model and execute all cells of the notebook. Generated images during training will be placed in `./images/cycle-gan/<model-name>/<dataset-name>/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"fdcgan\"\n",
    "# model = \"resnet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"apple2orange64\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import itertools\n",
    "import datetime\n",
    "import time\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters and Datasets Specific Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Global Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 17         # epoch to start training from\n",
    "n_epochs = 200          # number of epochs of training\n",
    "decay_epoch=100         # epoch from which to start lr decay\n",
    "n_cpu=8                 # number of cpu threads to use during batch generation\n",
    "lr = 0.0002             # adam: learning rate\n",
    "b1 = 0.5                # adam: decay of first order momentum of gradient\n",
    "b2 = 0.999              # adam: decay of first order momentum of gradient\n",
    "n_cpu = 8               # number of cpu threads to use during batch generation\n",
    "sample_interval = 200   # interval between image samples\n",
    "checkpoint_interval = 1 # interval between batches for saving model checkpoints\n",
    "lambda_id = 5.0         # identity loss weight\n",
    "lambda_cyc = 10.0       # cycle loss weight\n",
    "if model == \"fdcgan\":\n",
    "    lambda_id = 1.0 \n",
    "    lambda_cyc = 2.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datasets Specifications**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"apple2orange64\":\n",
    "    batch_size = 4      # size of the batches\n",
    "    img_size = 64       # size of each image dimension\n",
    "    channels = 3        # rgb\n",
    "    \n",
    "else:\n",
    "    raise Exception(\"Unknown dataset\")\n",
    "\n",
    "print({\n",
    "    \"n_epochs\": n_epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"lr\": lr,\n",
    "    \"b1\": b1,\n",
    "    \"b2\": b2,\n",
    "    \"n_cpu\": n_cpu,\n",
    "    \"img_size\": img_size,\n",
    "    \"channels\": channels,\n",
    "    \"sample_interval\": sample_interval\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Chosen Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model == \"fdcgan\" or model == \"resnet\":\n",
    "    if model == \"fdcgan\":\n",
    "        from fdcgan import Generator, Discriminator, weights_init_normal\n",
    "    elif model == \"resnet\":\n",
    "        from resnet import Generator, Discriminator, weights_init_normal\n",
    "        n_residual_blocks = 9\n",
    "\n",
    "else:\n",
    "    raise Exception(\"Unknown model\")\n",
    "\n",
    "img_shape = (channels, img_size, img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Progress and Checkpoint Directories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_progress_folder = \"images/cycle-gan/%s/%s/\" % (model, dataset)\n",
    "\n",
    "os.makedirs(image_progress_folder, exist_ok=True)\n",
    "os.makedirs(\"./saved_models/cycle-gan/%s/%s\" % (model, dataset), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting Up Cuda**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "print(\"Device use for training: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Loss functions -- #\n",
    "\n",
    "if model == \"fdcgan\":\n",
    "    adversarial_loss = torch.nn.BCELoss()\n",
    "elif model == \"resnet\":\n",
    "    adversarial_loss = torch.nn.MSELoss()\n",
    "\n",
    "identity_loss = torch.nn.L1Loss()\n",
    "criterion_cycle = torch.nn.L1Loss()\n",
    "\n",
    "# -- Initialize generator and discriminator -- #\n",
    "\n",
    "if model == \"fdcgan\":\n",
    "    G_AB = Generator(img_shape)\n",
    "    G_BA = Generator(img_shape)\n",
    "elif model == \"resnet\":\n",
    "    G_AB = Generator(img_shape, n_residual_blocks)\n",
    "    G_BA = Generator(img_shape, n_residual_blocks)\n",
    "\n",
    "D_A = Discriminator(img_shape)\n",
    "D_B = Discriminator(img_shape)\n",
    "\n",
    "if cuda:\n",
    "    G_AB.cuda()\n",
    "    G_BA.cuda()\n",
    "    D_A.cuda()\n",
    "    D_B.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "    identity_loss.cuda()\n",
    "    criterion_cycle.cuda()\n",
    "\n",
    "if start_epoch != 0:\n",
    "    # Load pretrained models\n",
    "    G_AB.load_state_dict(torch.load(\"saved_models/cycle-gan/%s/%s/G_AB_%d.pth\" % (model, dataset, start_epoch)))\n",
    "    G_BA.load_state_dict(torch.load(\"saved_models/cycle-gan/%s/%s/G_BA_%d.pth\" % (model, dataset, start_epoch)))\n",
    "    D_A.load_state_dict(torch.load(\"saved_models/cycle-gan/%s/%s/D_A_%d.pth\" % (model, dataset, start_epoch)))\n",
    "    D_B.load_state_dict(torch.load(\"saved_models/cycle-gan/%s/%s/D_B_%d.pth\" % (model, dataset, start_epoch)))\n",
    "else:\n",
    "    # Initialize weights\n",
    "    if model == \"dcgan\" or model == \"fdcgan\" or model == \"resnet\":\n",
    "        G_AB.apply(weights_init_normal)\n",
    "        G_BA.apply(weights_init_normal)\n",
    "        D_A.apply(weights_init_normal)\n",
    "        D_B.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaLR:\n",
    "    def __init__(self, n_epochs, offset, decay_start_epoch):\n",
    "        assert (n_epochs - decay_start_epoch) > 0, \"Decay must start before the training session ends!\"\n",
    "        self.n_epochs = n_epochs\n",
    "        self.offset = offset\n",
    "        self.decay_start_epoch = decay_start_epoch\n",
    "\n",
    "    def step(self, epoch):\n",
    "        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch) / (self.n_epochs - self.decay_start_epoch)\n",
    "\n",
    "optimizer_G = torch.optim.Adam(\n",
    "    itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=lr, betas=(b1, b2)\n",
    ")\n",
    "optimizer_D_A = torch.optim.Adam(D_A.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D_B = torch.optim.Adam(D_B.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "# Learning rate update schedulers\n",
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer_G, lr_lambda=LambdaLR(n_epochs, start_epoch, decay_epoch).step\n",
    ")\n",
    "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer_D_A, lr_lambda=LambdaLR(n_epochs, start_epoch, decay_epoch).step\n",
    ")\n",
    "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer_D_B, lr_lambda=LambdaLR(n_epochs, start_epoch, decay_epoch).step\n",
    ")\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Buffers of previously generated samples:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size=50):\n",
    "        assert max_size > 0, \"Empty buffer or trying to create a black hole. Be careful.\"\n",
    "        self.max_size = max_size\n",
    "        self.data = []\n",
    "\n",
    "    def push_and_pop(self, data):\n",
    "        to_return = []\n",
    "        for element in data.data:\n",
    "            element = torch.unsqueeze(element, 0)\n",
    "            if len(self.data) < self.max_size:\n",
    "                self.data.append(element)\n",
    "                to_return.append(element)\n",
    "            else:\n",
    "                if random.uniform(0, 1) > 0.5:\n",
    "                    i = random.randint(0, self.max_size - 1)\n",
    "                    to_return.append(self.data[i].clone())\n",
    "                    self.data[i] = element\n",
    "                else:\n",
    "                    to_return.append(element)\n",
    "        return Variable(torch.cat(to_return))\n",
    "        \n",
    "fake_A_buffer = ReplayBuffer()\n",
    "fake_B_buffer = ReplayBuffer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_rgb(image):\n",
    "    rgb_image = Image.new(\"RGB\", image.size)\n",
    "    rgb_image.paste(image)\n",
    "    return rgb_image\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, transforms_=None, unaligned=False, mode=\"train\"):\n",
    "        self.transform = transforms.Compose(transforms_)\n",
    "        self.unaligned = unaligned\n",
    "\n",
    "        self.files_A = sorted(glob.glob(os.path.join(root, \"%s/A\" % mode) + \"/*.*\"))\n",
    "        self.files_B = sorted(glob.glob(os.path.join(root, \"%s/B\" % mode) + \"/*.*\"))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_A = Image.open(self.files_A[index % len(self.files_A)])\n",
    "\n",
    "        if self.unaligned:\n",
    "            image_B = Image.open(self.files_B[random.randint(0, len(self.files_B) - 1)])\n",
    "        else:\n",
    "            image_B = Image.open(self.files_B[index % len(self.files_B)])\n",
    "\n",
    "        # Convert grayscale images to rgb\n",
    "        if image_A.mode != \"RGB\":\n",
    "            image_A = to_rgb(image_A)\n",
    "        if image_B.mode != \"RGB\":\n",
    "            image_B = to_rgb(image_B)\n",
    "\n",
    "        item_A = self.transform(image_A)\n",
    "        item_B = self.transform(image_B)\n",
    "        return {\"A\": item_A, \"B\": item_B}\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.files_A), len(self.files_B))\n",
    "\n",
    "transforms_ = [\n",
    "    transforms.Resize(int(img_size * 1.12), Image.BICUBIC),\n",
    "    transforms.RandomCrop((img_size, img_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "]\n",
    "\n",
    "if dataset == \"apple2orange64\":\n",
    "\n",
    "    import subprocess\n",
    "    command = \"bash ./datasets/download_cyclegan_dataset.sh\"\n",
    "    subprocess.run(command, shell=True)\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        ImageDataset(\"./datasets/apple2orange64\", transforms_=transforms_, unaligned=True, mode=\"train\"),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=n_cpu,\n",
    "    )\n",
    "\n",
    "    # Test data loader\n",
    "    val_dataloader = DataLoader(\n",
    "        ImageDataset(\"./datasets/apple2orange64\", transforms_=transforms_, unaligned=True, mode=\"validation\"),\n",
    "        batch_size=5,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "    )\n",
    "\n",
    "def sample_images(batches_done):\n",
    "    \"\"\"Saves a generated sample from the test set\"\"\"\n",
    "    imgs = next(iter(val_dataloader))\n",
    "    G_AB.eval()\n",
    "    G_BA.eval()\n",
    "    real_A = Variable(imgs[\"A\"].type(Tensor))\n",
    "    fake_B = G_AB(real_A)\n",
    "    real_B = Variable(imgs[\"B\"].type(Tensor))\n",
    "    fake_A = G_BA(real_B)\n",
    "    # Arange images along x-axis\n",
    "    real_A = make_grid(real_A, nrow=5, normalize=True)\n",
    "    real_B = make_grid(real_B, nrow=5, normalize=True)\n",
    "    fake_A = make_grid(fake_A, nrow=5, normalize=True)\n",
    "    fake_B = make_grid(fake_B, nrow=5, normalize=True)\n",
    "    # Arange images along y-axis\n",
    "    image_grid = torch.cat((real_A, fake_B, real_B, fake_A), 1)\n",
    "    print(\"saving to \", batches_done)\n",
    "    save_image(image_grid, \"images/cycle-gan/%s/%s/%s.png\" % (model, dataset, batches_done), normalize=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately depending on how the dataset is imported we need to do separated training loops for mnist and apple2orange but the procedure is exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Using '{model}' with '{dataset}', saving progress to '{image_progress_folder}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_time = time.time()\n",
    "for epoch in range(start_epoch, n_epochs):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "\n",
    "        # Set model input\n",
    "        real_A = Variable(batch[\"A\"].type(Tensor))\n",
    "        real_B = Variable(batch[\"B\"].type(Tensor))\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(np.ones((real_A.size(0), *D_A.output_shape))), requires_grad=False)\n",
    "        fake = Variable(Tensor(np.zeros((real_A.size(0), *D_A.output_shape))), requires_grad=False)\n",
    "\n",
    "        # ------------------\n",
    "        #  Train Generators\n",
    "        # ------------------\n",
    "\n",
    "        G_AB.train()\n",
    "        G_BA.train()\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Identity loss\n",
    "        loss_id_A = identity_loss(G_BA(real_A), real_A)\n",
    "        loss_id_B = identity_loss(G_AB(real_B), real_B)\n",
    "\n",
    "        loss_identity = (loss_id_A + loss_id_B) / 2\n",
    "\n",
    "        # GAN loss\n",
    "        fake_B = G_AB(real_A)\n",
    "        loss_GAN_AB = adversarial_loss(D_B(fake_B), valid)\n",
    "        fake_A = G_BA(real_B)\n",
    "        loss_GAN_BA = adversarial_loss(D_A(fake_A), valid)\n",
    "\n",
    "        loss_GAN = (loss_GAN_AB + loss_GAN_BA) / 2\n",
    "\n",
    "        # Cycle loss\n",
    "        recov_A = G_BA(fake_B)\n",
    "        loss_cycle_A = criterion_cycle(recov_A, real_A)\n",
    "        recov_B = G_AB(fake_A)\n",
    "        loss_cycle_B = criterion_cycle(recov_B, real_B)\n",
    "\n",
    "        loss_cycle = (loss_cycle_A + loss_cycle_B) / 2\n",
    "\n",
    "        # Total loss\n",
    "        loss_G = loss_GAN + lambda_cyc * loss_cycle + lambda_id * loss_identity\n",
    "\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # -----------------------\n",
    "        #  Train Discriminator A\n",
    "        # -----------------------\n",
    "\n",
    "        optimizer_D_A.zero_grad()\n",
    "\n",
    "        # Real loss\n",
    "        loss_real = adversarial_loss(D_A(real_A), valid)\n",
    "        # Fake loss (on batch of previously generated samples)\n",
    "        fake_A_ = fake_A_buffer.push_and_pop(fake_A)\n",
    "        loss_fake = adversarial_loss(D_A(fake_A_.detach()), fake)\n",
    "        # Total loss\n",
    "        loss_D_A = (loss_real + loss_fake) / 2\n",
    "\n",
    "        loss_D_A.backward()\n",
    "        optimizer_D_A.step()\n",
    "\n",
    "        # -----------------------\n",
    "        #  Train Discriminator B\n",
    "        # -----------------------\n",
    "\n",
    "        optimizer_D_B.zero_grad()\n",
    "\n",
    "        # Real loss\n",
    "        loss_real = adversarial_loss(D_B(real_B), valid)\n",
    "        # Fake loss (on batch of previously generated samples)\n",
    "        fake_B_ = fake_B_buffer.push_and_pop(fake_B)\n",
    "        loss_fake = adversarial_loss(D_B(fake_B_.detach()), fake)\n",
    "        # Total loss\n",
    "        loss_D_B = (loss_real + loss_fake) / 2\n",
    "\n",
    "        loss_D_B.backward()\n",
    "        optimizer_D_B.step()\n",
    "\n",
    "        loss_D = (loss_D_A + loss_D_B) / 2\n",
    "\n",
    "        # --------------\n",
    "        #  Log Progress\n",
    "        # --------------\n",
    "\n",
    "        # Determine approximate time left\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        batches_left = n_epochs * len(dataloader) - batches_done\n",
    "        time_left = datetime.timedelta(seconds=batches_left * (time.time() - prev_time))\n",
    "        prev_time = time.time()\n",
    "\n",
    "        # Print log\n",
    "        sys.stdout.write(\n",
    "            \"\\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f, adv: %f, cycle: %f, identity: %f] ETA: %s\"\n",
    "            % (\n",
    "                epoch,\n",
    "                n_epochs,\n",
    "                i,\n",
    "                len(dataloader),\n",
    "                loss_D.item(),\n",
    "                loss_G.item(),\n",
    "                loss_GAN.item(),\n",
    "                loss_cycle.item(),\n",
    "                loss_identity.item(),\n",
    "                time_left,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # If at sample interval save image\n",
    "        if batches_done % sample_interval == 0:\n",
    "            sample_images(batches_done)\n",
    "\n",
    "    # Update learning rates\n",
    "    lr_scheduler_G.step()\n",
    "    lr_scheduler_D_A.step()\n",
    "    lr_scheduler_D_B.step()\n",
    "\n",
    "    if checkpoint_interval != -1 and epoch % checkpoint_interval == 0:\n",
    "        # Save model checkpoints\n",
    "        torch.save(G_AB.state_dict(), \"saved_models/cycle-gan/%s/%s/G_AB_%d.pth\" % (model, dataset, epoch))\n",
    "        torch.save(G_BA.state_dict(), \"saved_models/cycle-gan/%s/%s/G_BA_%d.pth\" % (model, dataset, epoch))\n",
    "        torch.save(D_A.state_dict(), \"saved_models/cycle-gan/%s/%s/D_A_%d.pth\" % (model, dataset, epoch))\n",
    "        torch.save(D_B.state_dict(), \"saved_models/cycle-gan/%s/%s/D_B_%d.pth\" % (model, dataset, epoch))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GAN_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
